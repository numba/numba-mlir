{
    "microbenchmarks.dispatcher.numba_mlir.DispatcherArrayArg.time_dispatcher": {
        "code": "class DispatcherArrayArg:\n    def time_dispatcher(self, preset):\n        self.func(*self.args)\n\n    def setup(self, preset):\n        def func(*args):\n            pass\n    \n        self.func = njit(func)\n        self.args = _array_params[preset]\n        self.func(*self.args)",
        "min_run_count": 2,
        "name": "microbenchmarks.dispatcher.numba_mlir.DispatcherArrayArg.time_dispatcher",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'1'",
                "'2-same'",
                "'2-different'",
                "'6-same'",
                "'6-different'",
                "'12-same'",
                "'12-different'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "microbenchmarks.dispatcher.numba_mlir.DispatcherFuncArg.time_dispatcher": {
        "code": "class DispatcherFuncArg:\n    def time_dispatcher(self, preset):\n        self.func(*self.args)\n\n    def setup(self, preset):\n        def func(*args):\n            pass\n    \n        self.func = njit(func)\n        self.args = _func_params[preset]\n        self.func(*self.args)",
        "min_run_count": 2,
        "name": "microbenchmarks.dispatcher.numba_mlir.DispatcherFuncArg.time_dispatcher",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'1'",
                "'2-same'",
                "'2-different'",
                "'6-same'",
                "'6-different'",
                "'12-same'",
                "'12-different'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "microbenchmarks.dispatcher.numba_mlir.DispatcherTrivialArgs.time_dispatcher": {
        "code": "class DispatcherTrivialArgs:\n    def time_dispatcher(self, preset):\n        self.func(*self.args)\n\n    def setup(self, preset):\n        def func(*args):\n            pass\n    \n        self.func = njit(func)\n        self.args = _trivial_params[preset]\n        self.func(*self.args)",
        "min_run_count": 2,
        "name": "microbenchmarks.dispatcher.numba_mlir.DispatcherTrivialArgs.time_dispatcher",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'1'",
                "'2-same'",
                "'2-different'",
                "'6-same'",
                "'6-different'",
                "'12-same'",
                "'12-different'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "microbenchmarks.kernel_dispatcher.numba_mlir.KernelDispatcher.time_dispatcher": {
        "code": "class KernelDispatcher:\n    def time_dispatcher(self, count, device):\n        self.func(*self.args)\n\n    @skip_benchmark_if(not has_dpctl())\n    def setup(self, count, device):\n        import dpctl.tensor as dpt\n    \n        array = dpt.empty(8, dtype=np.int32)\n    \n        func = kernel(get_func(count))\n        self.base_func = func\n        self.func = func[8, DEFAULT_LOCAL_SIZE]\n        self.args = (array,) * count\n        self.base_func[8, DEFAULT_LOCAL_SIZE](*self.args)\n        self.func(*self.args)",
        "min_run_count": 2,
        "name": "microbenchmarks.kernel_dispatcher.numba_mlir.KernelDispatcher.time_dispatcher",
        "number": 0,
        "param_names": [
            "count",
            "device"
        ],
        "params": [
            [
                "1",
                "2",
                "6",
                "12"
            ],
            [
                "'opencl:gpu:0'",
                "'opencl:cpu:0'",
                "'level_zero:gpu:0'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "microbenchmarks.kernel_dispatcher.numba_mlir.KernelDispatcher.time_full_dispatcher": {
        "code": "class KernelDispatcher:\n    def time_full_dispatcher(self, count, device):\n        self.base_func[8, DEFAULT_LOCAL_SIZE](*self.args)\n\n    @skip_benchmark_if(not has_dpctl())\n    def setup(self, count, device):\n        import dpctl.tensor as dpt\n    \n        array = dpt.empty(8, dtype=np.int32)\n    \n        func = kernel(get_func(count))\n        self.base_func = func\n        self.func = func[8, DEFAULT_LOCAL_SIZE]\n        self.args = (array,) * count\n        self.base_func[8, DEFAULT_LOCAL_SIZE](*self.args)\n        self.func(*self.args)",
        "min_run_count": 2,
        "name": "microbenchmarks.kernel_dispatcher.numba_mlir.KernelDispatcher.time_full_dispatcher",
        "number": 0,
        "param_names": [
            "count",
            "device"
        ],
        "params": [
            [
                "1",
                "2",
                "6",
                "12"
            ],
            [
                "'opencl:gpu:0'",
                "'opencl:cpu:0'",
                "'level_zero:gpu:0'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.azimint_hist.numba.Benchmark.time_benchmark": {
        "code": "@jit\ndef azimint_hist(data, radius, npt):\n    histu = np.histogram(radius, npt)[0]\n    # histw = np.histogram(radius, npt, weights=data)[0]\n    histw = histogram_prange(radius, npt, weights=data)[0]\n    return histw / histu\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = self.is_validate\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.azimint_hist.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.azimint_hist.numba_mlir.Benchmark.time_benchmark": {
        "code": "@jit\ndef azimint_hist(data, radius, npt):\n    histu = np.histogram(radius, npt)[0]\n    # histw = np.histogram(radius, npt, weights=data)[0]\n    histw = histogram_prange(radius, npt, weights=data)[0]\n    return histw / histu\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = True\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.azimint_hist.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.azimint_hist.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "@jit\ndef azimint_hist(data, radius, npt):\n    histu = np.histogram(radius, npt)[0]\n    # histw = np.histogram(radius, npt, weights=data)[0]\n    histw = histogram_prange(radius, npt, weights=data)[0]\n    return histw / histu\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = self.is_validate\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.azimint_hist.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.azimint_hist.numpy.Benchmark.time_benchmark": {
        "code": "def azimint_hist(data, radius, npt):\n    histu = np.histogram(radius, npt)[0]\n    histw = np.histogram(radius, npt, weights=data)[0]\n    return histw / histu\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.azimint_hist.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.azimint_naive.numba.Benchmark.time_benchmark": {
        "code": "def azimint_naive(data, radius, npt):\n    rmax = radius.max()\n    res = np.zeros(npt, dtype=np.float64)\n    for i in prange(npt):\n        r1 = rmax * i / npt\n        r2 = rmax * (i + 1) / npt\n        mask_r12 = np.logical_and((r1 <= radius), (radius < r2))\n        values_r12 = data[mask_r12]\n        res[i] = values_r12.mean()\n    return res\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.azimint_naive.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.azimint_naive.numba_mlir.Benchmark.time_benchmark": {
        "code": "def azimint_naive(data, radius, npt):\n    rmax = radius.max()\n    res = np.zeros(npt, dtype=np.float64)\n    for i in prange(npt):\n        r1 = rmax * i / npt\n        r2 = rmax * (i + 1) / npt\n        mask_r12 = np.logical_and((r1 <= radius), (radius < r2))\n        values_r12 = data[mask_r12]\n        res[i] = values_r12.mean()\n    return res\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.azimint_naive.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.azimint_naive.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "def azimint_naive(data, radius, npt):\n    rmax = radius.max()\n    res = np.zeros(npt, dtype=np.float64)\n    for i in prange(npt):\n        r1 = rmax * i / npt\n        r2 = rmax * (i + 1) / npt\n        mask_r12 = np.logical_and((r1 <= radius), (radius < r2))\n        values_r12 = data[mask_r12]\n        res[i] = values_r12.mean()\n    return res\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.azimint_naive.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.azimint_naive.numpy.Benchmark.time_benchmark": {
        "code": "def azimint_naive(data, radius, npt):\n    rmax = radius.max()\n    res = np.zeros(npt, dtype=np.float64)\n    for i in prange(npt):\n        r1 = rmax * i / npt\n        r2 = rmax * (i + 1) / npt\n        mask_r12 = np.logical_and((r1 <= radius), (radius < r2))\n        values_r12 = data[mask_r12]\n        res[i] = values_r12.mean()\n    return res\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.azimint_naive.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.cavity_flow.numba.Benchmark.time_benchmark": {
        "code": "def wrapper(nx, ny, nt, nit, u, v, dt, dx, dy, p, rho, nu):\n    cavity_flow(nx, ny, nt, nit, u, v, dt, dx, dy, p, rho, nu)\n    return u, v, p, dx, dy, dt\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.cavity_flow.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.cavity_flow.numba_mlir.Benchmark.time_benchmark": {
        "code": "def wrapper(nx, ny, nt, nit, u, v, dt, dx, dy, p, rho, nu):\n    cavity_flow(nx, ny, nt, nit, u, v, dt, dx, dy, p, rho, nu)\n    return u, v, p, dx, dy, dt\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.cavity_flow.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.cavity_flow.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "def wrapper(nx, ny, nt, nit, u, v, dt, dx, dy, p, rho, nu):\n    cavity_flow(nx, ny, nt, nit, u, v, dt, dx, dy, p, rho, nu)\n    return u, v, p, dx, dy, dt\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.cavity_flow.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.cavity_flow.numpy.Benchmark.time_benchmark": {
        "code": "def wrapper(nx, ny, nt, nit, u, v, dt, dx, dy, p, rho, nu):\n    cavity_flow(nx, ny, nt, nit, u, v, dt, dx, dy, p, rho, nu)\n    return u, v, p, dx, dy, dt\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.cavity_flow.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.channel_flow.numba.Benchmark.time_benchmark": {
        "code": "def wrapper(nit, u, v, dt, dx, dy, p, rho, nu, F):\n    channel_flow(nit, u, v, dt, dx, dy, p, rho, nu, F)\n    return u, v, p, dx, dy, dt\n\n\ndef initialize(self, preset):\n    if self.is_validate:\n        raise SkipNotImplemented(\"too slow\")\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.channel_flow.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.channel_flow.numba_mlir.Benchmark.time_benchmark": {
        "code": "def wrapper(nit, u, v, dt, dx, dy, p, rho, nu, F):\n    channel_flow(nit, u, v, dt, dx, dy, p, rho, nu, F)\n    return u, v, p, dx, dy, dt\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.channel_flow.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.channel_flow.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "def wrapper(nit, u, v, dt, dx, dy, p, rho, nu, F):\n    channel_flow(nit, u, v, dt, dx, dy, p, rho, nu, F)\n    return u, v, p, dx, dy, dt\n\n\ndef initialize(self, preset):\n    if self.is_validate:\n        raise SkipNotImplemented(\"too slow\")\n    self.is_expected_failure = True\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.channel_flow.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.channel_flow.numpy.Benchmark.time_benchmark": {
        "code": "def wrapper(nit, u, v, dt, dx, dy, p, rho, nu, F):\n    channel_flow(nit, u, v, dt, dx, dy, p, rho, nu, F)\n    return u, v, p, dx, dy, dt\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.channel_flow.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.compute.numba.Benchmark.time_benchmark": {
        "code": "def compute(array_1, array_2, a, b, c):\n    return np.clip(array_1, 2, 10) * a + array_2 * b + c\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.compute.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.compute.numba_mlir.Benchmark.time_benchmark": {
        "code": "def compute(array_1, array_2, a, b, c):\n    return np.clip(array_1, 2, 10) * a + array_2 * b + c\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = True  # np.clip\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.compute.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.compute.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "def compute(array_1, array_2, a, b, c):\n    return np.clip(array_1, 2, 10) * a + array_2 * b + c\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.compute.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.compute.numpy.Benchmark.time_benchmark": {
        "code": "def compute(array_1, array_2, a, b, c):\n    return np.clip(array_1, 2, 10) * a + array_2 * b + c\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.compute.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.contour_integral.numba.Benchmark.time_benchmark": {
        "code": "def contour_integral(NR, NM, slab_per_bc, Ham, int_pts, Y):\n    P0 = np.zeros((NR, NM), dtype=np.complex128)\n    P1 = np.zeros((NR, NM), dtype=np.complex128)\n    for z in int_pts:\n        Tz = np.zeros((NR, NR), dtype=np.complex128)\n        for n in range(slab_per_bc + 1):\n            zz = np.power(z, slab_per_bc / 2 - n)\n            Tz += zz * Ham[n]\n        if NR == NM:\n            X = np.linalg.inv(Tz)\n        else:\n            X = np.linalg.solve(Tz, Y)\n        if abs(z) < 1.0:\n            X = -X\n        P0 += X\n        P1 += z * X\n\n    return P0, P1\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.contour_integral.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.contour_integral.numba_mlir.Benchmark.time_benchmark": {
        "code": "def contour_integral(NR, NM, slab_per_bc, Ham, int_pts, Y):\n    P0 = np.zeros((NR, NM), dtype=np.complex128)\n    P1 = np.zeros((NR, NM), dtype=np.complex128)\n    for z in int_pts:\n        Tz = np.zeros((NR, NR), dtype=np.complex128)\n        for n in range(slab_per_bc + 1):\n            zz = np.power(z, slab_per_bc / 2 - n)\n            Tz += zz * Ham[n]\n        if NR == NM:\n            X = np.linalg.inv(Tz)\n        else:\n            X = np.linalg.solve(Tz, Y)\n        if abs(z) < 1.0:\n            X = -X\n        P0 += X\n        P1 += z * X\n\n    return P0, P1\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = True  # np.linalg.inv\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.contour_integral.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.contour_integral.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "def contour_integral(NR, NM, slab_per_bc, Ham, int_pts, Y):\n    P0 = np.zeros((NR, NM), dtype=np.complex128)\n    P1 = np.zeros((NR, NM), dtype=np.complex128)\n    for z in int_pts:\n        Tz = np.zeros((NR, NR), dtype=np.complex128)\n        for n in range(slab_per_bc + 1):\n            zz = np.power(z, slab_per_bc / 2 - n)\n            Tz += zz * Ham[n]\n        if NR == NM:\n            X = np.linalg.inv(Tz)\n        else:\n            X = np.linalg.solve(Tz, Y)\n        if abs(z) < 1.0:\n            X = -X\n        P0 += X\n        P1 += z * X\n\n    return P0, P1\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = True  # asfortranarray\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.contour_integral.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.contour_integral.numpy.Benchmark.time_benchmark": {
        "code": "def contour_integral(NR, NM, slab_per_bc, Ham, int_pts, Y):\n    P0 = np.zeros((NR, NM), dtype=np.complex128)\n    P1 = np.zeros((NR, NM), dtype=np.complex128)\n    for z in int_pts:\n        Tz = np.zeros((NR, NR), dtype=np.complex128)\n        for n in range(slab_per_bc + 1):\n            zz = np.power(z, slab_per_bc / 2 - n)\n            Tz += zz * Ham[n]\n        if NR == NM:\n            X = np.linalg.inv(Tz)\n        else:\n            X = np.linalg.solve(Tz, Y)\n        if abs(z) < 1.0:\n            X = -X\n        P0 += X\n        P1 += z * X\n\n    return P0, P1\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.contour_integral.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.crc16.numba.Benchmark.time_benchmark": {
        "code": "def crc16(data, poly=0x8408):\n    \"\"\"\n    CRC-16-CCITT Algorithm\n    \"\"\"\n    crc = 0xFFFF\n    for b in data:\n        cur_byte = 0xFF & b\n        for _ in range(0, 8):\n            if (crc & 0x0001) ^ (cur_byte & 0x0001):\n                crc = (crc >> 1) ^ poly\n            else:\n                crc >>= 1\n            cur_byte >>= 1\n    crc = ~crc & 0xFFFF\n    crc = (crc << 8) | ((crc >> 8) & 0xFF)\n\n    return crc & 0xFFFF\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.crc16.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.crc16.numba_mlir.Benchmark.time_benchmark": {
        "code": "def crc16(data, poly=0x8408):\n    \"\"\"\n    CRC-16-CCITT Algorithm\n    \"\"\"\n    crc = 0xFFFF\n    for b in data:\n        cur_byte = 0xFF & b\n        for _ in range(0, 8):\n            if (crc & 0x0001) ^ (cur_byte & 0x0001):\n                crc = (crc >> 1) ^ poly\n            else:\n                crc >>= 1\n            cur_byte >>= 1\n    crc = ~crc & 0xFFFF\n    crc = (crc << 8) | ((crc >> 8) & 0xFF)\n\n    return crc & 0xFFFF\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.crc16.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.crc16.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "def crc16(data, poly=0x8408):\n    \"\"\"\n    CRC-16-CCITT Algorithm\n    \"\"\"\n    crc = 0xFFFF\n    for b in data:\n        cur_byte = 0xFF & b\n        for _ in range(0, 8):\n            if (crc & 0x0001) ^ (cur_byte & 0x0001):\n                crc = (crc >> 1) ^ poly\n            else:\n                crc >>= 1\n            cur_byte >>= 1\n    crc = ~crc & 0xFFFF\n    crc = (crc << 8) | ((crc >> 8) & 0xFF)\n\n    return crc & 0xFFFF\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.crc16.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.crc16.numpy.Benchmark.time_benchmark": {
        "code": "def crc16(data, poly=0x8408):\n    \"\"\"\n    CRC-16-CCITT Algorithm\n    \"\"\"\n    crc = 0xFFFF\n    for b in data:\n        cur_byte = 0xFF & b\n        for _ in range(0, 8):\n            if (crc & 0x0001) ^ (cur_byte & 0x0001):\n                crc = (crc >> 1) ^ poly\n            else:\n                crc >>= 1\n            cur_byte >>= 1\n    crc = ~crc & 0xFFFF\n    crc = (crc << 8) | ((crc >> 8) & 0xFF)\n\n    return crc & 0xFFFF\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.crc16.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.conv2d_bias.numba.Benchmark.time_benchmark": {
        "code": "@jit\ndef conv2d_bias(input, weights, bias):\n    return conv2d(input, weights) + bias\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.conv2d_bias.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.conv2d_bias.numba_mlir.Benchmark.time_benchmark": {
        "code": "@jit\ndef conv2d_bias(input, weights, bias):\n    return conv2d(input, weights) + bias\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.conv2d_bias.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.conv2d_bias.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "@jit\ndef conv2d_bias(input, weights, bias):\n    return conv2d(input, weights) + bias\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.conv2d_bias.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.conv2d_bias.numpy.Benchmark.time_benchmark": {
        "code": "@jit\ndef conv2d_bias(input, weights, bias):\n    return conv2d(input, weights) + bias\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.conv2d_bias.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.lenet.numba.Benchmark.time_benchmark": {
        "code": "@jit\ndef lenet5(\n    input,\n    conv1,\n    conv1bias,\n    conv2,\n    conv2bias,\n    fc1w,\n    fc1b,\n    fc2w,\n    fc2b,\n    fc3w,\n    fc3b,\n    N,\n    C_before_fc1,\n):\n    x = relu(conv2d(input, conv1) + conv1bias)\n    x = maxpool2d(x)\n    x = relu(conv2d(x, conv2) + conv2bias)\n    x = maxpool2d(x)\n    x = np.reshape(x, (N, C_before_fc1))\n    x = relu(x @ fc1w + fc1b)\n    x = relu(x @ fc2w + fc2b)\n    return x @ fc3w + fc3b\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.lenet.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.lenet.numba_mlir.Benchmark.time_benchmark": {
        "code": "@jit\ndef lenet5(\n    input,\n    conv1,\n    conv1bias,\n    conv2,\n    conv2bias,\n    fc1w,\n    fc1b,\n    fc2w,\n    fc2b,\n    fc3w,\n    fc3b,\n    N,\n    C_before_fc1,\n):\n    x = relu(conv2d(input, conv1) + conv1bias)\n    x = maxpool2d(x)\n    x = relu(conv2d(x, conv2) + conv2bias)\n    x = maxpool2d(x)\n    x = np.reshape(x, (N, C_before_fc1))\n    x = relu(x @ fc1w + fc1b)\n    x = relu(x @ fc2w + fc2b)\n    return x @ fc3w + fc3b\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.lenet.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.lenet.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "@jit\ndef lenet5(\n    input,\n    conv1,\n    conv1bias,\n    conv2,\n    conv2bias,\n    fc1w,\n    fc1b,\n    fc2w,\n    fc2b,\n    fc3w,\n    fc3b,\n    N,\n    C_before_fc1,\n):\n    x = relu(conv2d(input, conv1) + conv1bias)\n    x = maxpool2d(x)\n    x = relu(conv2d(x, conv2) + conv2bias)\n    x = maxpool2d(x)\n    x = np.reshape(x, (N, C_before_fc1))\n    x = relu(x @ fc1w + fc1b)\n    x = relu(x @ fc2w + fc2b)\n    return x @ fc3w + fc3b\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = True\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.lenet.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.lenet.numpy.Benchmark.time_benchmark": {
        "code": "@jit\ndef lenet5(\n    input,\n    conv1,\n    conv1bias,\n    conv2,\n    conv2bias,\n    fc1w,\n    fc1b,\n    fc2w,\n    fc2b,\n    fc3w,\n    fc3b,\n    N,\n    C_before_fc1,\n):\n    x = relu(conv2d(input, conv1) + conv1bias)\n    x = maxpool2d(x)\n    x = relu(conv2d(x, conv2) + conv2bias)\n    x = maxpool2d(x)\n    x = np.reshape(x, (N, C_before_fc1))\n    x = relu(x @ fc1w + fc1b)\n    x = relu(x @ fc2w + fc2b)\n    return x @ fc3w + fc3b\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.lenet.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.mlp.numba.Benchmark.time_benchmark": {
        "code": "@jit\ndef mlp(input, w1, b1, w2, b2, w3, b3):\n    x = relu(input @ w1 + b1)\n    x = relu(x @ w2 + b2)\n    x = softmax(x @ w3 + b3)  # Softmax call can be omitted if necessary\n    return x\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.mlp.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.mlp.numba_mlir.Benchmark.time_benchmark": {
        "code": "@jit\ndef mlp(input, w1, b1, w2, b2, w3, b3):\n    x = relu(input @ w1 + b1)\n    x = relu(x @ w2 + b2)\n    x = softmax(x @ w3 + b3)  # Softmax call can be omitted if necessary\n    return x\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.mlp.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.mlp.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "@jit\ndef mlp(input, w1, b1, w2, b2, w3, b3):\n    x = relu(input @ w1 + b1)\n    x = relu(x @ w2 + b2)\n    x = softmax(x @ w3 + b3)  # Softmax call can be omitted if necessary\n    return x\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = True\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.mlp.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.mlp.numpy.Benchmark.time_benchmark": {
        "code": "@jit\ndef mlp(input, w1, b1, w2, b2, w3, b3):\n    x = relu(input @ w1 + b1)\n    x = relu(x @ w2 + b2)\n    x = softmax(x @ w3 + b3)  # Softmax call can be omitted if necessary\n    return x\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.mlp.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.resnet.numba.Benchmark.time_benchmark": {
        "code": "@jit\ndef resnet_basicblock(input, conv1, conv2, conv3):\n    # Pad output of first convolution for second convolution\n    padded = np.zeros(\n        (input.shape[0], input.shape[1] + 2, input.shape[2] + 2, conv1.shape[3])\n    )\n\n    padded[:, 1:-1, 1:-1, :] = conv2d(input, conv1)\n    x = batchnorm2d(padded)\n    x = relu(x)\n\n    x = conv2d(x, conv2)\n    x = batchnorm2d(x)\n    x = relu(x)\n    x = conv2d(x, conv3)\n    x = batchnorm2d(x)\n    return relu(x + input)\n\n\ndef initialize(self, preset):\n    raise SkipNotImplemented(\"timeout\")\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.resnet.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.resnet.numba_mlir.Benchmark.time_benchmark": {
        "code": "@jit\ndef resnet_basicblock(input, conv1, conv2, conv3):\n    # Pad output of first convolution for second convolution\n    padded = np.zeros(\n        (input.shape[0], input.shape[1] + 2, input.shape[2] + 2, conv1.shape[3])\n    )\n\n    padded[:, 1:-1, 1:-1, :] = conv2d(input, conv1)\n    x = batchnorm2d(padded)\n    x = relu(x)\n\n    x = conv2d(x, conv2)\n    x = batchnorm2d(x)\n    x = relu(x)\n    x = conv2d(x, conv3)\n    x = batchnorm2d(x)\n    return relu(x + input)\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.resnet.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.resnet.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "@jit\ndef resnet_basicblock(input, conv1, conv2, conv3):\n    # Pad output of first convolution for second convolution\n    padded = np.zeros(\n        (input.shape[0], input.shape[1] + 2, input.shape[2] + 2, conv1.shape[3])\n    )\n\n    padded[:, 1:-1, 1:-1, :] = conv2d(input, conv1)\n    x = batchnorm2d(padded)\n    x = relu(x)\n\n    x = conv2d(x, conv2)\n    x = batchnorm2d(x)\n    x = relu(x)\n    x = conv2d(x, conv3)\n    x = batchnorm2d(x)\n    return relu(x + input)\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = True\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.resnet.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.resnet.numpy.Benchmark.time_benchmark": {
        "code": "@jit\ndef resnet_basicblock(input, conv1, conv2, conv3):\n    # Pad output of first convolution for second convolution\n    padded = np.zeros(\n        (input.shape[0], input.shape[1] + 2, input.shape[2] + 2, conv1.shape[3])\n    )\n\n    padded[:, 1:-1, 1:-1, :] = conv2d(input, conv1)\n    x = batchnorm2d(padded)\n    x = relu(x)\n\n    x = conv2d(x, conv2)\n    x = batchnorm2d(x)\n    x = relu(x)\n    x = conv2d(x, conv3)\n    x = batchnorm2d(x)\n    return relu(x + input)\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.resnet.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.softmax.numba.Benchmark.time_benchmark": {
        "code": "@jit\ndef softmax(x):\n    new_shape = (x.shape[0], x.shape[1], x.shape[2], 1)\n    # tmp_max = np.max(x, axis=-1, keepdims=True)\n    tmp_max = np.empty(new_shape, dtype=x.dtype)\n    for i in prange(x.shape[3]):\n        tmp_max[:, :, :, 0] = np.max(x[:, :, :, i])\n    tmp_out = np.exp(x - tmp_max)\n    # tmp_sum = np.sum(tmp_out, axis=-1, keepdims=True)\n    tmp_sum = np.reshape(np.sum(tmp_out, axis=-1), new_shape)\n    return tmp_out / tmp_sum\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.softmax.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.softmax.numba_mlir.Benchmark.time_benchmark": {
        "code": "@jit\ndef softmax(x):\n    tmp_max = np.max(x, axis=-1, keepdims=True)\n    tmp_out = np.exp(x - tmp_max)\n    tmp_sum = np.sum(tmp_out, axis=-1, keepdims=True)\n    return tmp_out / tmp_sum\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.softmax.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.softmax.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "@jit\ndef softmax(x):\n    new_shape = (x.shape[0], x.shape[1], x.shape[2], 1)\n    # tmp_max = np.max(x, axis=-1, keepdims=True)\n    tmp_max = np.empty(new_shape, dtype=x.dtype)\n    for i in prange(x.shape[3]):\n        tmp_max[:, :, :, 0] = np.max(x[:, :, :, i])\n    tmp_out = np.exp(x - tmp_max)\n    # tmp_sum = np.sum(tmp_out, axis=-1, keepdims=True)\n    tmp_sum = np.reshape(np.sum(tmp_out, axis=-1), new_shape)\n    return tmp_out / tmp_sum\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = True\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.softmax.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.deep_learning.softmax.numpy.Benchmark.time_benchmark": {
        "code": "@jit\ndef softmax(x):\n    tmp_max = np.max(x, axis=-1, keepdims=True)\n    tmp_out = np.exp(x - tmp_max)\n    tmp_sum = np.sum(tmp_out, axis=-1, keepdims=True)\n    return tmp_out / tmp_sum\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.deep_learning.softmax.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.go_fast.numba.Benchmark.time_benchmark": {
        "code": "def go_fast(a):\n    trace = 0.0\n    for i in prange(a.shape[0]):\n        trace += np.tanh(a[i, i])\n    return a + trace\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.go_fast.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.go_fast.numba_mlir.Benchmark.time_benchmark": {
        "code": "def go_fast(a):\n    trace = 0.0\n    for i in prange(a.shape[0]):\n        trace += np.tanh(a[i, i])\n    return a + trace\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.go_fast.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.go_fast.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "def go_fast(a):\n    trace = 0.0\n    for i in prange(a.shape[0]):\n        trace += np.tanh(a[i, i])\n    return a + trace\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.go_fast.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.go_fast.numpy.Benchmark.time_benchmark": {
        "code": "def go_fast(a):\n    trace = 0.0\n    for i in prange(a.shape[0]):\n        trace += np.tanh(a[i, i])\n    return a + trace\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.go_fast.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.mandelbrot1.numba.Benchmark.time_benchmark": {
        "code": "@jit\ndef mandelbrot(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0):\n    # Adapted from https://www.ibm.com/developerworks/community/blogs/jfp/...\n    #              .../entry/How_To_Compute_Mandelbrodt_Set_Quickly?lang=en\n    # X = np.linspace(xmin, xmax, xn, dtype=np.float64)\n    # Y = np.linspace(ymin, ymax, yn, dtype=np.float64)\n    X = linspace(xmin, xmax, xn, dtype=np.float64)\n    Y = linspace(ymin, ymax, yn, dtype=np.float64)\n    # C = X + Y[:,None]*1j\n    C = X + np.reshape(Y, (yn, 1)) * 1j\n    N = np.zeros(C.shape, dtype=np.int64)\n    Z = np.zeros(C.shape, dtype=np.complex128)\n    for n in range(maxiter):\n        # I = np.less(abs(Z), horizon)\n        I = np.less(np.absolute(Z), horizon)  # noqa: E741 math variable\n        # N[I] = n\n        for j in prange(C.shape[0]):\n            for k in prange(C.shape[1]):\n                if I[j, k]:\n                    N[j, k] = n\n                    # Z[I] = Z[I]**2 + C[I]\n                    # for j in prange(C.shape[0]):\n                    #    for k in prange(C.shape[1]):\n                    #:        if I[j, k]:\n                    Z[j, k] = Z[j, k] ** 2 + C[j, k]\n    # N[N == maxiter-1] = 0\n    for j in prange(C.shape[0]):\n        for k in prange(C.shape[1]):\n            if N[j, k] == maxiter - 1:\n                N[j, k] = 0\n    return Z, N\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.mandelbrot1.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.mandelbrot1.numba_mlir.Benchmark.time_benchmark": {
        "code": "@jit\ndef mandelbrot(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0):\n    # Adapted from https://www.ibm.com/developerworks/community/blogs/jfp/...\n    #              .../entry/How_To_Compute_Mandelbrodt_Set_Quickly?lang=en\n    # X = np.linspace(xmin, xmax, xn, dtype=np.float64)\n    # Y = np.linspace(ymin, ymax, yn, dtype=np.float64)\n    X = linspace(xmin, xmax, xn, dtype=np.float64)\n    Y = linspace(ymin, ymax, yn, dtype=np.float64)\n    # C = X + Y[:,None]*1j\n    C = X + np.reshape(Y, (yn, 1)) * 1j\n    N = np.zeros(C.shape, dtype=np.int64)\n    Z = np.zeros(C.shape, dtype=np.complex128)\n    for n in range(maxiter):\n        # I = np.less(abs(Z), horizon)\n        I = np.less(np.absolute(Z), horizon)  # noqa: E741 math variable\n        # N[I] = n\n        for j in prange(C.shape[0]):\n            for k in prange(C.shape[1]):\n                if I[j, k]:\n                    N[j, k] = n\n                    # Z[I] = Z[I]**2 + C[I]\n                    # for j in prange(C.shape[0]):\n                    #    for k in prange(C.shape[1]):\n                    #:        if I[j, k]:\n                    Z[j, k] = Z[j, k] ** 2 + C[j, k]\n    # N[N == maxiter-1] = 0\n    for j in prange(C.shape[0]):\n        for k in prange(C.shape[1]):\n            if N[j, k] == maxiter - 1:\n                N[j, k] = 0\n    return Z, N\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.mandelbrot1.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.mandelbrot1.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "@jit\ndef mandelbrot(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0):\n    # Adapted from https://www.ibm.com/developerworks/community/blogs/jfp/...\n    #              .../entry/How_To_Compute_Mandelbrodt_Set_Quickly?lang=en\n    # X = np.linspace(xmin, xmax, xn, dtype=np.float64)\n    # Y = np.linspace(ymin, ymax, yn, dtype=np.float64)\n    X = linspace(xmin, xmax, xn, dtype=np.float64)\n    Y = linspace(ymin, ymax, yn, dtype=np.float64)\n    # C = X + Y[:,None]*1j\n    C = X + np.reshape(Y, (yn, 1)) * 1j\n    N = np.zeros(C.shape, dtype=np.int64)\n    Z = np.zeros(C.shape, dtype=np.complex128)\n    for n in range(maxiter):\n        # I = np.less(abs(Z), horizon)\n        I = np.less(np.absolute(Z), horizon)  # noqa: E741 math variable\n        # N[I] = n\n        for j in prange(C.shape[0]):\n            for k in prange(C.shape[1]):\n                if I[j, k]:\n                    N[j, k] = n\n                    # Z[I] = Z[I]**2 + C[I]\n                    # for j in prange(C.shape[0]):\n                    #    for k in prange(C.shape[1]):\n                    #:        if I[j, k]:\n                    Z[j, k] = Z[j, k] ** 2 + C[j, k]\n    # N[N == maxiter-1] = 0\n    for j in prange(C.shape[0]):\n        for k in prange(C.shape[1]):\n            if N[j, k] == maxiter - 1:\n                N[j, k] = 0\n    return Z, N\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.mandelbrot1.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.mandelbrot1.numpy.Benchmark.time_benchmark": {
        "code": "def mandelbrot(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0):\n    # Adapted from https://www.ibm.com/developerworks/community/blogs/jfp/...\n    #              .../entry/How_To_Compute_Mandelbrodt_Set_Quickly?lang=en\n    X = np.linspace(xmin, xmax, xn, dtype=np.float64)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float64)\n    C = X + Y[:, None] * 1j\n    N = np.zeros(C.shape, dtype=np.int64)\n    Z = np.zeros(C.shape, dtype=np.complex128)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)  # noqa: E741 math variable\n        N[I] = n\n        Z[I] = Z[I] ** 2 + C[I]\n    N[N == maxiter - 1] = 0\n    return Z, N\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.mandelbrot1.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.mandelbrot2.numba.Benchmark.time_benchmark": {
        "code": "@jit\ndef mandelbrot(xmin, xmax, ymin, ymax, xn, yn, itermax, horizon=2.0):\n    # Adapted from\n    # https://thesamovar.wordpress.com/2009/03/22/fast-fractals-with-python-and-numpy/\n    # Xi, Yi = np.mgrid[0:xn, 0:yn]\n    # X = np.linspace(xmin, xmax, xn, dtype=np.float64)[Xi]\n    # Y = np.linspace(ymin, ymax, yn, dtype=np.float64)[Yi]\n    Xi, Yi = mgrid(xn, yn)\n    X = linspace(xmin, xmax, xn, dtype=np.float64)\n    Y = linspace(ymin, ymax, yn, dtype=np.float64)\n    # C = X + Y*1j\n    C = np.reshape(X, (xn, 1)) + Y * 1j\n    N_ = np.zeros(C.shape, dtype=np.int64)\n    Z_ = np.zeros(C.shape, dtype=np.complex128)\n    # Xi.shape = Yi.shape = C.shape = xn*yn\n    Xi = np.reshape(Xi, (xn * yn))\n    Yi = np.reshape(Yi, (xn * yn))\n    C = np.reshape(C, (xn * yn))\n\n    Z = np.zeros(C.shape, np.complex128)\n    for i in range(itermax):\n        if not len(Z):\n            break\n\n        # Compute for relevant points only\n        np.multiply(Z, Z, Z)\n        np.add(Z, C, Z)\n\n        # Failed convergence\n        # I = abs(Z) > horizon\n        I = np.absolute(Z) > horizon  # noqa: E741 math variable\n        # N_[Xi[I], Yi[I]] = i+1\n        for j in range(I.shape[0]):\n            if I[j]:\n                N_[Xi[j], Yi[j]] = i + 1\n        # Z_[Xi[I], Yi[I]] = Z[I]\n        for j in range(I.shape[0]):\n            if I[j]:\n                Z_[Xi[j], Yi[j]] = Z[j]\n\n        # Keep going with those who have not diverged yet\n        np.logical_not(I, I)  # np.negative(I, I) not working any longer\n        Z = Z[I]\n        Xi, Yi = Xi[I], Yi[I]\n        C = C[I]\n    return Z_.T, N_.T\n\n\ndef initialize(self, preset):\n    raise SkipNotImplemented(\"crashes\")\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.mandelbrot2.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.mandelbrot2.numba_mlir.Benchmark.time_benchmark": {
        "code": "@jit\ndef mandelbrot(xmin, xmax, ymin, ymax, xn, yn, itermax, horizon=2.0):\n    # Adapted from\n    # https://thesamovar.wordpress.com/2009/03/22/fast-fractals-with-python-and-numpy/\n    # Xi, Yi = np.mgrid[0:xn, 0:yn]\n    # X = np.linspace(xmin, xmax, xn, dtype=np.float64)[Xi]\n    # Y = np.linspace(ymin, ymax, yn, dtype=np.float64)[Yi]\n    Xi, Yi = mgrid(xn, yn)\n    X = linspace(xmin, xmax, xn, dtype=np.float64)\n    Y = linspace(ymin, ymax, yn, dtype=np.float64)\n    # C = X + Y*1j\n    C = np.reshape(X, (xn, 1)) + Y * 1j\n    N_ = np.zeros(C.shape, dtype=np.int64)\n    Z_ = np.zeros(C.shape, dtype=np.complex128)\n    # Xi.shape = Yi.shape = C.shape = xn*yn\n    Xi = np.reshape(Xi, (xn * yn))\n    Yi = np.reshape(Yi, (xn * yn))\n    C = np.reshape(C, (xn * yn))\n\n    Z = np.zeros(C.shape, np.complex128)\n    for i in range(itermax):\n        if not len(Z):\n            break\n\n        # Compute for relevant points only\n        np.multiply(Z, Z, Z)\n        np.add(Z, C, Z)\n\n        # Failed convergence\n        # I = abs(Z) > horizon\n        I = np.absolute(Z) > horizon  # noqa: E741 math variable\n        # N_[Xi[I], Yi[I]] = i+1\n        for j in range(I.shape[0]):\n            if I[j]:\n                N_[Xi[j], Yi[j]] = i + 1\n        # Z_[Xi[I], Yi[I]] = Z[I]\n        for j in range(I.shape[0]):\n            if I[j]:\n                Z_[Xi[j], Yi[j]] = Z[j]\n\n        # Keep going with those who have not diverged yet\n        np.logical_not(I, I)  # np.negative(I, I) not working any longer\n        Z = Z[I]\n        Xi, Yi = Xi[I], Yi[I]\n        C = C[I]\n    return Z_.T, N_.T\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.mandelbrot2.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.mandelbrot2.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "@jit\ndef mandelbrot(xmin, xmax, ymin, ymax, xn, yn, itermax, horizon=2.0):\n    # Adapted from\n    # https://thesamovar.wordpress.com/2009/03/22/fast-fractals-with-python-and-numpy/\n    # Xi, Yi = np.mgrid[0:xn, 0:yn]\n    # X = np.linspace(xmin, xmax, xn, dtype=np.float64)[Xi]\n    # Y = np.linspace(ymin, ymax, yn, dtype=np.float64)[Yi]\n    Xi, Yi = mgrid(xn, yn)\n    X = linspace(xmin, xmax, xn, dtype=np.float64)\n    Y = linspace(ymin, ymax, yn, dtype=np.float64)\n    # C = X + Y*1j\n    C = np.reshape(X, (xn, 1)) + Y * 1j\n    N_ = np.zeros(C.shape, dtype=np.int64)\n    Z_ = np.zeros(C.shape, dtype=np.complex128)\n    # Xi.shape = Yi.shape = C.shape = xn*yn\n    Xi = np.reshape(Xi, (xn * yn))\n    Yi = np.reshape(Yi, (xn * yn))\n    C = np.reshape(C, (xn * yn))\n\n    Z = np.zeros(C.shape, np.complex128)\n    for i in range(itermax):\n        if not len(Z):\n            break\n\n        # Compute for relevant points only\n        np.multiply(Z, Z, Z)\n        np.add(Z, C, Z)\n\n        # Failed convergence\n        # I = abs(Z) > horizon\n        I = np.absolute(Z) > horizon  # noqa: E741 math variable\n        # N_[Xi[I], Yi[I]] = i+1\n        for j in range(I.shape[0]):\n            if I[j]:\n                N_[Xi[j], Yi[j]] = i + 1\n        # Z_[Xi[I], Yi[I]] = Z[I]\n        for j in range(I.shape[0]):\n            if I[j]:\n                Z_[Xi[j], Yi[j]] = Z[j]\n\n        # Keep going with those who have not diverged yet\n        np.logical_not(I, I)  # np.negative(I, I) not working any longer\n        Z = Z[I]\n        Xi, Yi = Xi[I], Yi[I]\n        C = C[I]\n    return Z_.T, N_.T\n\n\ndef initialize(self, preset):\n    raise SkipNotImplemented(\"crashes\")\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.mandelbrot2.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.mandelbrot2.numpy.Benchmark.time_benchmark": {
        "code": "def mandelbrot(xmin, xmax, ymin, ymax, xn, yn, itermax, horizon=2.0):\n    Xi, Yi = np.mgrid[0:xn, 0:yn]\n    X = np.linspace(xmin, xmax, xn, dtype=np.float64)[Xi]\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float64)[Yi]\n    C = X + Y * 1j\n    N_ = np.zeros(C.shape, dtype=np.int64)\n    Z_ = np.zeros(C.shape, dtype=np.complex128)\n    Xi.shape = Yi.shape = C.shape = xn * yn\n\n    Z = np.zeros(C.shape, np.complex128)\n    for i in range(itermax):\n        if not len(Z):\n            break\n\n        # Compute for relevant points only\n        np.multiply(Z, Z, Z)\n        np.add(Z, C, Z)\n\n        # Failed convergence\n        I = abs(Z) > horizon  # noqa: E741 math variable\n        N_[Xi[I], Yi[I]] = i + 1\n        Z_[Xi[I], Yi[I]] = Z[I]\n\n        # Keep going with those who have not diverged yet\n        np.logical_not(I, I)  # np.negative(I, I) not working any longer\n        Z = Z[I]\n        Xi, Yi = Xi[I], Yi[I]\n        C = C[I]\n    return Z_.T, N_.T\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.mandelbrot2.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.nbody.numba.Benchmark.time_benchmark": {
        "code": "@jit\ndef nbody(mass, pos, vel, N, Nt, dt, G, softening):\n    # Convert to Center-of-Mass frame\n    # vel -= np.mean(mass * vel, axis=0) / np.mean(mass)\n    vel -= (np.sum(mass * vel, axis=0) / vel.shape[0]) / np.mean(mass)\n\n    # calculate initial gravitational accelerations\n    acc = getAcc(pos, mass, G, softening)\n\n    # calculate initial energy of system\n    # KE = np.ndarray(Nt+1, dtype=np.float64)\n    # PE = np.ndarray(Nt+1, dtype=np.float64)\n    KE = np.empty(Nt + 1, dtype=np.float64)\n    PE = np.empty(Nt + 1, dtype=np.float64)\n    KE[0], PE[0] = getEnergy(pos, vel, mass, G)\n\n    t = 0.0\n\n    # Simulation Main Loop\n    for i in range(Nt):\n        # (1/2) kick\n        vel += acc * dt / 2.0\n\n        # drift\n        pos += vel * dt\n\n        # update accelerations\n        acc = getAcc(pos, mass, G, softening)\n\n        # (1/2) kick\n        vel += acc * dt / 2.0\n\n        # update time\n        t += dt\n\n        # get energy of system\n        KE[i + 1], PE[i + 1] = getEnergy(pos, vel, mass, G)\n\n    return KE, PE\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = True\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.nbody.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.nbody.numba_mlir.Benchmark.time_benchmark": {
        "code": "@jit\ndef nbody(mass, pos, vel, N, Nt, dt, G, softening):\n    # Convert to Center-of-Mass frame\n    # vel -= np.mean(mass * vel, axis=0) / np.mean(mass)\n    vel -= (np.sum(mass * vel, axis=0) / vel.shape[0]) / np.mean(mass)\n\n    # calculate initial gravitational accelerations\n    acc = getAcc(pos, mass, G, softening)\n\n    # calculate initial energy of system\n    # KE = np.ndarray(Nt+1, dtype=np.float64)\n    # PE = np.ndarray(Nt+1, dtype=np.float64)\n    KE = np.empty(Nt + 1, dtype=np.float64)\n    PE = np.empty(Nt + 1, dtype=np.float64)\n    KE[0], PE[0] = getEnergy(pos, vel, mass, G)\n\n    t = 0.0\n\n    # Simulation Main Loop\n    for i in range(Nt):\n        # (1/2) kick\n        vel += acc * dt / 2.0\n\n        # drift\n        pos += vel * dt\n\n        # update accelerations\n        acc = getAcc(pos, mass, G, softening)\n\n        # (1/2) kick\n        vel += acc * dt / 2.0\n\n        # update time\n        t += dt\n\n        # get energy of system\n        KE[i + 1], PE[i + 1] = getEnergy(pos, vel, mass, G)\n\n    return KE, PE\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = self.is_validate\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.nbody.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.nbody.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "@jit\ndef nbody(mass, pos, vel, N, Nt, dt, G, softening):\n    # Convert to Center-of-Mass frame\n    # vel -= np.mean(mass * vel, axis=0) / np.mean(mass)\n    vel -= (np.sum(mass * vel, axis=0) / vel.shape[0]) / np.mean(mass)\n\n    # calculate initial gravitational accelerations\n    acc = getAcc(pos, mass, G, softening)\n\n    # calculate initial energy of system\n    # KE = np.ndarray(Nt+1, dtype=np.float64)\n    # PE = np.ndarray(Nt+1, dtype=np.float64)\n    KE = np.empty(Nt + 1, dtype=np.float64)\n    PE = np.empty(Nt + 1, dtype=np.float64)\n    KE[0], PE[0] = getEnergy(pos, vel, mass, G)\n\n    t = 0.0\n\n    # Simulation Main Loop\n    for i in range(Nt):\n        # (1/2) kick\n        vel += acc * dt / 2.0\n\n        # drift\n        pos += vel * dt\n\n        # update accelerations\n        acc = getAcc(pos, mass, G, softening)\n\n        # (1/2) kick\n        vel += acc * dt / 2.0\n\n        # update time\n        t += dt\n\n        # get energy of system\n        KE[i + 1], PE[i + 1] = getEnergy(pos, vel, mass, G)\n\n    return KE, PE\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = True\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.nbody.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.nbody.numpy.Benchmark.time_benchmark": {
        "code": "@jit\ndef nbody(mass, pos, vel, N, Nt, dt, G, softening):\n    # Convert to Center-of-Mass frame\n    vel -= np.mean(mass * vel, axis=0) / np.mean(mass)\n\n    # calculate initial gravitational accelerations\n    acc = getAcc(pos, mass, G, softening)\n\n    # calculate initial energy of system\n    KE = np.ndarray(Nt + 1, dtype=np.float64)\n    PE = np.ndarray(Nt + 1, dtype=np.float64)\n    KE[0], PE[0] = getEnergy(pos, vel, mass, G)\n\n    t = 0.0\n\n    # Simulation Main Loop\n    for i in range(Nt):\n        # (1/2) kick\n        vel += acc * dt / 2.0\n\n        # drift\n        pos += vel * dt\n\n        # update accelerations\n        acc = getAcc(pos, mass, G, softening)\n\n        # (1/2) kick\n        vel += acc * dt / 2.0\n\n        # update time\n        t += dt\n\n        # get energy of system\n        KE[i + 1], PE[i + 1] = getEnergy(pos, vel, mass, G)\n\n    return KE, PE\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.nbody.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.pythran.arc_distance.numba.Benchmark.time_benchmark": {
        "code": "def arc_distance(theta_1, phi_1, theta_2, phi_2):\n    \"\"\"\n    Calculates the pairwise arc distance between all points in vector a and b.\n    \"\"\"\n    temp = (\n        np.sin((theta_2 - theta_1) / 2) ** 2\n        + np.cos(theta_1) * np.cos(theta_2) * np.sin((phi_2 - phi_1) / 2) ** 2\n    )\n    distance_matrix = 2 * (np.arctan2(np.sqrt(temp), np.sqrt(1 - temp)))\n    return distance_matrix\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.pythran.arc_distance.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.pythran.arc_distance.numba_mlir.Benchmark.time_benchmark": {
        "code": "def arc_distance(theta_1, phi_1, theta_2, phi_2):\n    \"\"\"\n    Calculates the pairwise arc distance between all points in vector a and b.\n    \"\"\"\n    temp = (\n        np.sin((theta_2 - theta_1) / 2) ** 2\n        + np.cos(theta_1) * np.cos(theta_2) * np.sin((phi_2 - phi_1) / 2) ** 2\n    )\n    distance_matrix = 2 * (np.arctan2(np.sqrt(temp), np.sqrt(1 - temp)))\n    return distance_matrix\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.pythran.arc_distance.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.pythran.arc_distance.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "def arc_distance(theta_1, phi_1, theta_2, phi_2):\n    \"\"\"\n    Calculates the pairwise arc distance between all points in vector a and b.\n    \"\"\"\n    temp = (\n        np.sin((theta_2 - theta_1) / 2) ** 2\n        + np.cos(theta_1) * np.cos(theta_2) * np.sin((phi_2 - phi_1) / 2) ** 2\n    )\n    distance_matrix = 2 * (np.arctan2(np.sqrt(temp), np.sqrt(1 - temp)))\n    return distance_matrix\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.pythran.arc_distance.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.pythran.arc_distance.numpy.Benchmark.time_benchmark": {
        "code": "def arc_distance(theta_1, phi_1, theta_2, phi_2):\n    \"\"\"\n    Calculates the pairwise arc distance between all points in vector a and b.\n    \"\"\"\n    temp = (\n        np.sin((theta_2 - theta_1) / 2) ** 2\n        + np.cos(theta_1) * np.cos(theta_2) * np.sin((phi_2 - phi_1) / 2) ** 2\n    )\n    distance_matrix = 2 * (np.arctan2(np.sqrt(temp), np.sqrt(1 - temp)))\n    return distance_matrix\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.pythran.arc_distance.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.scattering_self_energies.numba.Benchmark.time_benchmark": {
        "code": "def wrapper(neigh_idx, dH, G, D, Sigma):\n    scattering_self_energies(neigh_idx, dH, G, D, Sigma)\n    return Sigma\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.scattering_self_energies.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.scattering_self_energies.numba_mlir.Benchmark.time_benchmark": {
        "code": "def wrapper(neigh_idx, dH, G, D, Sigma):\n    scattering_self_energies(neigh_idx, dH, G, D, Sigma)\n    return Sigma\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.scattering_self_energies.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.scattering_self_energies.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "def wrapper(neigh_idx, dH, G, D, Sigma):\n    scattering_self_energies(neigh_idx, dH, G, D, Sigma)\n    return Sigma\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.scattering_self_energies.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.scattering_self_energies.numpy.Benchmark.time_benchmark": {
        "code": "def wrapper(neigh_idx, dH, G, D, Sigma):\n    scattering_self_energies(neigh_idx, dH, G, D, Sigma)\n    return Sigma\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.scattering_self_energies.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.spmv.numba.Benchmark.time_benchmark": {
        "code": "def spmv(A_row, A_col, A_val, x):\n    y = np.empty(A_row.size - 1, A_val.dtype)\n\n    for i in prange(A_row.size - 1):\n        cols = A_col[A_row[i] : A_row[i + 1]]\n        vals = A_val[A_row[i] : A_row[i + 1]]\n        y[i] = vals @ x[cols]\n\n    return y\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.spmv.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.spmv.numba_mlir.Benchmark.time_benchmark": {
        "code": "def spmv(A_row, A_col, A_val, x):\n    y = np.empty(A_row.size - 1, A_val.dtype)\n\n    for i in prange(A_row.size - 1):\n        cols = A_col[A_row[i] : A_row[i + 1]]\n        vals = A_val[A_row[i] : A_row[i + 1]]\n        y[i] = vals @ x[cols]\n\n    return y\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.spmv.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.spmv.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "def spmv(A_row, A_col, A_val, x):\n    y = np.empty(A_row.size - 1, A_val.dtype)\n\n    for i in prange(A_row.size - 1):\n        cols = A_col[A_row[i] : A_row[i + 1]]\n        vals = A_val[A_row[i] : A_row[i + 1]]\n        y[i] = vals @ x[cols]\n\n    return y\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.spmv.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.spmv.numpy.Benchmark.time_benchmark": {
        "code": "def spmv(A_row, A_col, A_val, x):\n    y = np.empty(A_row.size - 1, A_val.dtype)\n\n    for i in prange(A_row.size - 1):\n        cols = A_col[A_row[i] : A_row[i + 1]]\n        vals = A_val[A_row[i] : A_row[i + 1]]\n        y[i] = vals @ x[cols]\n\n    return y\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.spmv.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.stockham_fft.numba.Benchmark.time_benchmark": {
        "code": "def wrapper(N, R, K, x, y):\n    stockham_fft(N, R, K, x, y)\n    return y\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.stockham_fft.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.stockham_fft.numba_mlir.Benchmark.time_benchmark": {
        "code": "def wrapper(N, R, K, x, y):\n    stockham_fft(N, R, K, x, y)\n    return y\n\n\ndef initialize(self, preset):\n    self.is_expected_failure = True  # global pi\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.stockham_fft.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.stockham_fft.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "def wrapper(N, R, K, x, y):\n    stockham_fft(N, R, K, x, y)\n    return y\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.stockham_fft.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.stockham_fft.numpy.Benchmark.time_benchmark": {
        "code": "def wrapper(N, R, K, x, y):\n    stockham_fft(N, R, K, x, y)\n    return y\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.stockham_fft.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.weather_stencils.hdiff.numba.Benchmark.time_benchmark": {
        "code": "def wrapper(in_field, out_field, coeff):\n    hdiff(in_field, out_field, coeff)\n    return out_field\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.weather_stencils.hdiff.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.weather_stencils.hdiff.numba_mlir.Benchmark.time_benchmark": {
        "code": "def wrapper(in_field, out_field, coeff):\n    hdiff(in_field, out_field, coeff)\n    return out_field\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.weather_stencils.hdiff.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.weather_stencils.hdiff.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "def wrapper(in_field, out_field, coeff):\n    hdiff(in_field, out_field, coeff)\n    return out_field\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.weather_stencils.hdiff.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.weather_stencils.hdiff.numpy.Benchmark.time_benchmark": {
        "code": "def wrapper(in_field, out_field, coeff):\n    hdiff(in_field, out_field, coeff)\n    return out_field\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.weather_stencils.hdiff.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.weather_stencils.vadv.numba.Benchmark.time_benchmark": {
        "code": "def wrapper(utens_stage, u_stage, wcon, u_pos, utens, dtr_stage):\n    vadv(utens_stage, u_stage, wcon, u_pos, utens, dtr_stage)\n    return utens_stage\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.weather_stencils.vadv.numba.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.weather_stencils.vadv.numba_mlir.Benchmark.time_benchmark": {
        "code": "def wrapper(utens_stage, u_stage, wcon, u_pos, utens, dtr_stage):\n    vadv(utens_stage, u_stage, wcon, u_pos, utens, dtr_stage)\n    return utens_stage\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.weather_stencils.vadv.numba_mlir.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.weather_stencils.vadv.numba_replace_parfor.Benchmark.time_benchmark": {
        "code": "def wrapper(utens_stage, u_stage, wcon, u_pos, utens, dtr_stage):\n    vadv(utens_stage, u_stage, wcon, u_pos, utens, dtr_stage)\n    return utens_stage\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.weather_stencils.vadv.numba_replace_parfor.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "npbench.weather_stencils.vadv.numpy.Benchmark.time_benchmark": {
        "code": "def wrapper(utens_stage, u_stage, wcon, u_pos, utens, dtr_stage):\n    vadv(utens_stage, u_stage, wcon, u_pos, utens, dtr_stage)\n    return utens_stage\n\n\ndef initialize(self, preset):\n    preset = parameters[preset]\n    return initialize(**preset)",
        "min_run_count": 2,
        "name": "npbench.weather_stencils.vadv.numpy.Benchmark.time_benchmark",
        "number": 0,
        "param_names": [
            "preset"
        ],
        "params": [
            [
                "'S'",
                "'M'",
                "'paper'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "base",
        "warmup_time": -1
    },
    "version": 2
}